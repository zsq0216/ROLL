[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:29:15 [__init__.py:239] Automatically detected platform cuda.
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m [2026-02-02 05:29:16] [vllm_strategy.py (95)] [INFO] [actor_infer-0 0 / 1][PID 52146] vllm_config: {'gpu_memory_utilization': 0.8, 'block_size': 16, 'max_model_len': 512, 'enforce_eager': True, 'enable_prefix_caching': False, 'model': '/root/.cache/modelscope/hub/models/Qwen/Qwen2___5-Coder-0___5B', 'dtype': 'bfloat16', 'trust_remote_code': True, 'seed': 42, 'disable_custom_all_reduce': True, 'load_format': 'dummy'}
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:29:23 [config.py:689] This model supports multiple tasks: {'reward', 'embed', 'score', 'generate', 'classify'}. Defaulting to 'generate'.
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:29:23 [config.py:1901] Chunked prefill is enabled with max_num_batched_tokens=8192.
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m WARNING 02-02 05:29:23 [cuda.py:96] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m [2026-02-02 05:29:23] [llm_engine.py (179)] [INFO] [actor_infer-0 0 / 1][PID 52146] Using executor_class: <class 'vllm.v1.executor.abstract.UniProcExecutor'>
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m [2026-02-02 05:29:23] [llm_engine.py (180)] [INFO] [actor_infer-0 0 / 1][PID 52146] Using worker cls: roll.third_party.vllm.vllm_0_8_4.v1.worker.Worker084
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:29:27 [__init__.py:239] Automatically detected platform cuda.
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:29:29 [core.py:61] Initializing a V1 LLM engine (v0.8.4) with config: model='/root/.cache/modelscope/hub/models/Qwen/Qwen2___5-Coder-0___5B', speculative_config=None, tokenizer='/root/.cache/modelscope/hub/models/Qwen/Qwen2___5-Coder-0___5B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=512, download_dir=None, load_format=dummy, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=42, served_model_name=/root/.cache/modelscope/hub/models/Qwen/Qwen2___5-Coder-0___5B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m add logger: log_rank_actor_infer-0_0_1
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Created or verified log directory: ./output/logs/toy-0.5B-grpo-code
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Added logging to file: /workspace/ROLL/examples/output/logs/toy-0.5B-grpo-code/log_rank_actor_infer-0_0_1.log
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m [2026-02-02 05:29:30] [cuda.py (52)] [INFO] [actor_infer-0 0 / 1][PID 53084] Successfully imported vLLM V1 Worker.
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m WARNING 02-02 05:29:30 [utils.py:2444] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <roll.third_party.vllm.vllm_0_8_4.v1.worker.Worker084 object at 0x784226d3c400>
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:29:30 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:29:30 [cuda.py:221] Using Flash Attention backend on V1 engine.
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:29:30 [gpu_model_runner.py:1276] Starting to load model /root/.cache/modelscope/hub/models/Qwen/Qwen2___5-Coder-0___5B...
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m WARNING 02-02 05:29:30 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:29:31 [gpu_model_runner.py:1291] Model loading took 0.9277 GiB and 0.116380 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:29:31 [kv_cache_utils.py:634] GPU KV cache size: 3,070,704 tokens
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:29:31 [kv_cache_utils.py:637] Maximum concurrency for 512 tokens per request: 5997.47x
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:29:31 [core.py:163] init engine (profile, create kv cache, warmup model) took 0.72 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:29:31 [core_client.py:435] Core engine process 0 ready.
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m [2026-02-02 05:29:31] [vllm_strategy.py (120)] [INFO] [actor_infer-0 0 / 1][PID 52146] add [AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True)] to additional_special_tokens: ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>', '<|endoftext|>']
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m [2026-02-02 05:29:31] [vllm_strategy.py (472)] [WARNING] [actor_infer-0 0 / 1][PID 52146] Failed to get metrics: 'Llm084' object has no attribute 'get_metrics'
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m [2026-02-02 05:29:31] [base_worker.py (62)] [INFO] [actor_infer-0 0 / 1][PID 52146] actor_infer-0 initialized
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:29:31 [block_pool.py:264] Successfully reset prefix cache
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:29:33 [gpu_worker.py:81] Sleep mode freed 37.52 GiB memory, 0.51 GiB memory is still in use.
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m [2026-02-02 05:29:40] [worker_helper.py (70)] [INFO] [actor_infer-0 0 / 1][PID 53084] no comm_plan found for rank 0/0
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m /usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py:391: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m   warnings.warn(
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m /usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py:417: FutureWarning: torch.cuda.reset_max_memory_cached now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m   warnings.warn(
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m [2026-02-02 05:32:11] [base_worker.py (146)] [INFO] [actor_infer-0 0 / 1][PID 52146] actor_infer-0 generate global step 0
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m [2026-02-02 05:32:11] [context_managers.py (41)] [INFO] [actor_infer-0 0 / 1][PID 52146] actor_infer/generate_start_offload, memory allocated (GB): 0.0, memory reserved (GB): 0.25, memory max reserved (GB): 0.25, rss (GB): 1.3669548034667969 memory device used (GB): 4.6005859375
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:32:11 [block_pool.py:264] Successfully reset prefix cache
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m [2026-02-02 05:32:11] [context_managers.py (41)] [INFO] [actor_infer-0 0 / 1][PID 52146] actor_infer/generate_start_onload, memory allocated (GB): 0.0, memory reserved (GB): 0.25, memory max reserved (GB): 0.25, rss (GB): 1.3669548034667969 memory device used (GB): 39.7568359375
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 0.0285 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 5.6565 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m [2026-02-02 05:32:16] [context_managers.py (41)] [INFO] [actor_infer-0 0 / 1][PID 52146] actor_infer/generate_end_onload, memory allocated (GB): 0.0, memory reserved (GB): 0.251953125, memory max reserved (GB): 0.251953125, rss (GB): 1.5718803405761719 memory device used (GB): 39.8193359375
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:32:16 [block_pool.py:264] Successfully reset prefix cache
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:32:17 [gpu_worker.py:81] Sleep mode freed 36.91 GiB memory, 2.42 GiB memory is still in use.
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m [2026-02-02 05:32:17] [context_managers.py (41)] [INFO] [actor_infer-0 0 / 1][PID 52146] actor_infer/generate_end_offload, memory allocated (GB): 0.0, memory reserved (GB): 0.0, memory max reserved (GB): 0.251953125, rss (GB): 1.5718803405761719 memory device used (GB): 2.6533203125
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 0.9569 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 6.6421 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m [2026-02-02 05:35:10] [base_worker.py (146)] [INFO] [actor_infer-0 0 / 1][PID 52146] actor_infer-0 generate global step 1
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m [2026-02-02 05:35:10] [context_managers.py (41)] [INFO] [actor_infer-0 0 / 1][PID 52146] actor_infer/generate_start_offload, memory allocated (GB): 0.0, memory reserved (GB): 0.25, memory max reserved (GB): 0.25, rss (GB): 1.5909690856933594 memory device used (GB): 4.9951171875
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:35:10 [block_pool.py:264] Successfully reset prefix cache
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m [2026-02-02 05:35:10] [context_managers.py (41)] [INFO] [actor_infer-0 0 / 1][PID 52146] actor_infer/generate_start_onload, memory allocated (GB): 0.0, memory reserved (GB): 0.25, memory max reserved (GB): 0.25, rss (GB): 1.5909690856933594 memory device used (GB): 40.1513671875
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 0.0271 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 5.6504 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m [2026-02-02 05:35:15] [context_managers.py (41)] [INFO] [actor_infer-0 0 / 1][PID 52146] actor_infer/generate_end_onload, memory allocated (GB): 0.0, memory reserved (GB): 0.251953125, memory max reserved (GB): 0.251953125, rss (GB): 1.5909690856933594 memory device used (GB): 40.1533203125
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:35:15 [block_pool.py:264] Successfully reset prefix cache
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:35:16 [gpu_worker.py:81] Sleep mode freed 36.91 GiB memory, 2.75 GiB memory is still in use.
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m [2026-02-02 05:35:16] [context_managers.py (41)] [INFO] [actor_infer-0 0 / 1][PID 52146] actor_infer/generate_end_offload, memory allocated (GB): 0.0, memory reserved (GB): 0.0, memory max reserved (GB): 0.251953125, rss (GB): 1.5909690856933594 memory device used (GB): 2.9873046875
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 1.1456 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 6.8232 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m [2026-02-02 05:38:04] [base_worker.py (146)] [INFO] [actor_infer-0 0 / 1][PID 52146] actor_infer-0 generate global step 2
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m [2026-02-02 05:38:04] [context_managers.py (41)] [INFO] [actor_infer-0 0 / 1][PID 52146] actor_infer/generate_start_offload, memory allocated (GB): 0.0, memory reserved (GB): 0.25, memory max reserved (GB): 0.25, rss (GB): 1.591217041015625 memory device used (GB): 4.9951171875
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:38:04 [block_pool.py:264] Successfully reset prefix cache
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m [2026-02-02 05:38:04] [context_managers.py (41)] [INFO] [actor_infer-0 0 / 1][PID 52146] actor_infer/generate_start_onload, memory allocated (GB): 0.0, memory reserved (GB): 0.25, memory max reserved (GB): 0.25, rss (GB): 1.591217041015625 memory device used (GB): 40.1513671875
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 0.0277 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 5.5137 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m [2026-02-02 05:38:10] [context_managers.py (41)] [INFO] [actor_infer-0 0 / 1][PID 52146] actor_infer/generate_end_onload, memory allocated (GB): 0.0, memory reserved (GB): 0.251953125, memory max reserved (GB): 0.251953125, rss (GB): 1.59136962890625 memory device used (GB): 40.1533203125
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:38:10 [block_pool.py:264] Successfully reset prefix cache
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:38:10 [gpu_worker.py:81] Sleep mode freed 36.91 GiB memory, 2.75 GiB memory is still in use.
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m [2026-02-02 05:38:11] [context_managers.py (41)] [INFO] [actor_infer-0 0 / 1][PID 52146] actor_infer/generate_end_offload, memory allocated (GB): 0.0, memory reserved (GB): 0.0, memory max reserved (GB): 0.251953125, rss (GB): 1.59136962890625 memory device used (GB): 2.9873046875
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 1.0540 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 6.5956 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m [2026-02-02 05:40:58] [base_worker.py (146)] [INFO] [actor_infer-0 0 / 1][PID 52146] actor_infer-0 generate global step 3
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m [2026-02-02 05:40:58] [context_managers.py (41)] [INFO] [actor_infer-0 0 / 1][PID 52146] actor_infer/generate_start_offload, memory allocated (GB): 0.0, memory reserved (GB): 0.25, memory max reserved (GB): 0.25, rss (GB): 1.5915451049804688 memory device used (GB): 4.9951171875
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:40:58 [block_pool.py:264] Successfully reset prefix cache
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m [2026-02-02 05:40:58] [context_managers.py (41)] [INFO] [actor_infer-0 0 / 1][PID 52146] actor_infer/generate_start_onload, memory allocated (GB): 0.0, memory reserved (GB): 0.25, memory max reserved (GB): 0.25, rss (GB): 1.5915451049804688 memory device used (GB): 40.1513671875
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 0.0368 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 5.5203 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m [2026-02-02 05:41:04] [context_managers.py (41)] [INFO] [actor_infer-0 0 / 1][PID 52146] actor_infer/generate_end_onload, memory allocated (GB): 0.0, memory reserved (GB): 0.251953125, memory max reserved (GB): 0.251953125, rss (GB): 1.5915451049804688 memory device used (GB): 40.1533203125
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:41:04 [block_pool.py:264] Successfully reset prefix cache
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:41:04 [gpu_worker.py:81] Sleep mode freed 36.91 GiB memory, 2.75 GiB memory is still in use.
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m [2026-02-02 05:41:05] [context_managers.py (41)] [INFO] [actor_infer-0 0 / 1][PID 52146] actor_infer/generate_end_offload, memory allocated (GB): 0.0, memory reserved (GB): 0.0, memory max reserved (GB): 0.251953125, rss (GB): 1.5915451049804688 memory device used (GB): 2.9873046875
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 0.8992 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 6.4564 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m [2026-02-02 05:43:53] [base_worker.py (146)] [INFO] [actor_infer-0 0 / 1][PID 52146] actor_infer-0 generate global step 4
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m [2026-02-02 05:43:53] [context_managers.py (41)] [INFO] [actor_infer-0 0 / 1][PID 52146] actor_infer/generate_start_offload, memory allocated (GB): 0.0, memory reserved (GB): 0.25, memory max reserved (GB): 0.25, rss (GB): 1.5919952392578125 memory device used (GB): 4.9951171875
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:43:53 [block_pool.py:264] Successfully reset prefix cache
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m [2026-02-02 05:43:53] [context_managers.py (41)] [INFO] [actor_infer-0 0 / 1][PID 52146] actor_infer/generate_start_onload, memory allocated (GB): 0.0, memory reserved (GB): 0.25, memory max reserved (GB): 0.25, rss (GB): 1.5919952392578125 memory device used (GB): 40.1513671875
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 0.0285 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 5.4401 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m [2026-02-02 05:43:58] [context_managers.py (41)] [INFO] [actor_infer-0 0 / 1][PID 52146] actor_infer/generate_end_onload, memory allocated (GB): 0.0, memory reserved (GB): 0.251953125, memory max reserved (GB): 0.251953125, rss (GB): 1.5919952392578125 memory device used (GB): 40.1533203125
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:43:58 [block_pool.py:264] Successfully reset prefix cache
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:43:59 [gpu_worker.py:81] Sleep mode freed 36.91 GiB memory, 2.75 GiB memory is still in use.
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m [2026-02-02 05:43:59] [context_managers.py (41)] [INFO] [actor_infer-0 0 / 1][PID 52146] actor_infer/generate_end_offload, memory allocated (GB): 0.0, memory reserved (GB): 0.0, memory max reserved (GB): 0.251953125, rss (GB): 1.5919952392578125 memory device used (GB): 2.9873046875
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 0.9817 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 6.4505 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m [2026-02-02 05:46:48] [base_worker.py (146)] [INFO] [actor_infer-0 0 / 1][PID 52146] actor_infer-0 generate global step 5
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m [2026-02-02 05:46:48] [context_managers.py (41)] [INFO] [actor_infer-0 0 / 1][PID 52146] actor_infer/generate_start_offload, memory allocated (GB): 0.0, memory reserved (GB): 0.25, memory max reserved (GB): 0.25, rss (GB): 1.5920677185058594 memory device used (GB): 4.9951171875
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:46:48 [block_pool.py:264] Successfully reset prefix cache
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 0.0268 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 5.0554 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:46:53 [block_pool.py:264] Successfully reset prefix cache
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:46:54 [gpu_worker.py:81] Sleep mode freed 36.91 GiB memory, 2.75 GiB memory is still in use.
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 1.0894 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 6.1718 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m [2026-02-02 05:49:45] [base_worker.py (146)] [INFO] [actor_infer-0 0 / 1][PID 52146] actor_infer-0 generate global step 6
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:49:45 [block_pool.py:264] Successfully reset prefix cache
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 0.0268 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 5.2929 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:49:50 [block_pool.py:264] Successfully reset prefix cache
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:49:50 [gpu_worker.py:81] Sleep mode freed 36.91 GiB memory, 2.75 GiB memory is still in use.
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 0.9004 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 6.2203 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m [2026-02-02 05:52:41] [base_worker.py (146)] [INFO] [actor_infer-0 0 / 1][PID 52146] actor_infer-0 generate global step 7
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:52:41 [block_pool.py:264] Successfully reset prefix cache
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 0.0272 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 5.3836 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:52:47 [block_pool.py:264] Successfully reset prefix cache
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:52:47 [gpu_worker.py:81] Sleep mode freed 36.91 GiB memory, 2.75 GiB memory is still in use.
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 0.9259 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 6.3369 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m [2026-02-02 05:55:38] [base_worker.py (146)] [INFO] [actor_infer-0 0 / 1][PID 52146] actor_infer-0 generate global step 8
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:55:38 [block_pool.py:264] Successfully reset prefix cache
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 0.0270 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 5.4067 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:55:44 [block_pool.py:264] Successfully reset prefix cache
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:55:44 [gpu_worker.py:81] Sleep mode freed 36.91 GiB memory, 2.75 GiB memory is still in use.
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 1.1912 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 6.6252 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m [2026-02-02 05:58:37] [base_worker.py (146)] [INFO] [actor_infer-0 0 / 1][PID 52146] actor_infer-0 generate global step 9
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:58:37 [block_pool.py:264] Successfully reset prefix cache
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 0.0371 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 5.6655 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:58:43 [block_pool.py:264] Successfully reset prefix cache
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m INFO 02-02 05:58:43 [gpu_worker.py:81] Sleep mode freed 36.91 GiB memory, 2.75 GiB memory is still in use.
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 0.8919 seconds
[36m(ActorWorker(actor_infer-0) pid=52146, ip=172.17.0.2)[0m Elapsed time: 6.5947 seconds
